# linear_classifier.py

import numpy as np

class SimpleLinearClassifier:
    def __init__(self, input_dim):
        self.weights = np.zeros(input_dim)
        self.bias = 0.0

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def predict(self, X):
        linear_combination = np.dot(X, self.weights) + self.bias
        return self.sigmoid(linear_combination)

    def binary_cross_entropy(self, y_true, y_pred):
        epsilon = 1e-15
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(y_pred))

    def train(self, X, y, epochs=1000, lr=0.01):
        for epoch in range(epochs):
            y_pred = self.predict(X)
            loss = self.binary_cross_entropy(y, y_pred)

            # Gradient calculation
            dw = np.dot(X.T, (y_pred - y)) / len(y)
            db = np.sum(y_pred - y) / len(y)

            # Update weights and bias
            self.weights -= lr * dw
            self.bias -= lr * db

            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Loss: {loss}")

# Example usage
if __name__ == "__main__":
    # Sample data (X: features, y: labels)
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 0, 0, 1])

    # Initialize and train the classifier
    classifier = SimpleLinearClassifier(input_dim=2)
    classifier.train(X, y, epochs=1000, lr=0.1)

    # Make predictions
    predictions = classifier.predict(X)
    print("Predictions:", predictions)